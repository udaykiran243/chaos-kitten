from __future__ import annotations

"""The Brain Orchestrator - Main agent logic using LangGraph."""

import asyncio
import json
import logging
from functools import partial
from typing import Any, Dict, List, Literal, TypedDict

try:
    from langgraph.graph import END, START, StateGraph
    HAS_LANGGRAPH = True
except (ImportError, TypeError):
    HAS_LANGGRAPH = False
from rich.console import Console
from rich.progress import (
    BarColumn,
    MofNCompleteColumn,
    Progress,
    SpinnerColumn,
    TextColumn,
)

from chaos_kitten.brain.attack_planner import AttackPlanner
from chaos_kitten.brain.openapi_parser import OpenAPIParser
from chaos_kitten.paws.analyzer import ResponseAnalyzer
from chaos_kitten.litterbox.reporter import Reporter
from chaos_kitten.paws.executor import Executor
from chaos_kitten.brain.recon import ReconEngine
from chaos_kitten.utils.checkpoint import (
    CheckpointData,
    calculate_config_hash,
    clean_checkpoint,
    load_checkpoint,
    save_checkpoint,
)

logger = logging.getLogger(__name__)
console = Console()


class AgentState(TypedDict):
    spec_path: str
    base_url: str
    endpoints: List[Dict[str, Any]]
    current_endpoint: int
    planned_attacks: List[Dict[str, Any]]
    results: List[Dict[str, Any]]
    findings: List[Dict[str, Any]]
    recon_results: Dict[str, Any]


async def run_recon(state: AgentState, app_config: Dict[str, Any]) -> Dict[str, Any]:
    # Renamed to app_config to avoid LangGraph collision
    console.print("[bold blue]ğŸ” Starting Reconnaissance Phase...[/bold blue]")
    try:
        engine = ReconEngine(app_config)
        
        # Run recon engine in an executor to avoid blocking the async loop
        loop = asyncio.get_running_loop()
        results = await loop.run_in_executor(None, engine.run)

        if results:
            subs = len(results.get('subdomains', []))
            techs = len(results.get('technologies', {}))
            console.print(f"[green]Recon complete: Found {subs} subdomains and fingerprint info for {techs} targets[/green]")
        return {"recon_results": results}
    except Exception as e:
        logger.exception("Reconnaissance failed")
        console.print(f"[red]Reconnaissance failed: {e}[/red]")
        return {"recon_results": {}}



def parse_openapi(state: AgentState) -> Dict[str, Any]:
    try:
        parser = OpenAPIParser(state["spec_path"])
        parser.parse()
        endpoints = parser.get_endpoints()
    except Exception:
        logger.exception("Failed to parse OpenAPI spec")
        raise
    return {"endpoints": endpoints, "current_endpoint": 0}


def plan_attacks(state: AgentState) -> Dict[str, Any]:
    idx = state["current_endpoint"]
    if idx >= len(state["endpoints"]):
        return {"planned_attacks": []}

    endpoint = state["endpoints"][idx]
    
    # In future, we can inject recon data into the planner context here.
    # For now, we trust the LLM to deduce context from the endpoint itself.
    
    planner = AttackPlanner([endpoint])
    return {"planned_attacks": planner.plan_attacks(endpoint)}


async def execute_and_analyze(state: AgentState, executor: Executor) -> Dict[str, Any]:
    idx = state["current_endpoint"]
    if idx >= len(state["endpoints"]):
        return {"findings": state["findings"], "current_endpoint": idx}

    endpoint = state["endpoints"][idx]
    analyzer = ResponseAnalyzer()

    new_findings = []

    for attack in state["planned_attacks"]:
        endpoint_path = endpoint.get("path")
        if not endpoint_path:
            logger.warning("Skipping attack - endpoint missing path: %s", endpoint)
            continue
        try:
            result = await executor.execute_attack(
                method=endpoint.get("method", "GET"),
                path=endpoint_path,
                payload=attack.get("payload"),
            )
        except Exception:
            logger.exception(
                "Attack execution failed for %s %s",
                endpoint.get("method"),
                endpoint.get("path"),
            )
            continue

        payload_obj = attack.get("payload")
        if payload_obj is None:
            payload_used = ""
        elif isinstance(payload_obj, dict):
            if len(payload_obj) == 1:
                only_value = next(iter(payload_obj.values()))
                payload_used = (
                    only_value if isinstance(only_value, str) else str(only_value)
                )
            else:
                payload_used = json.dumps(payload_obj, sort_keys=True, default=str, ensure_ascii=True)
        else:
            payload_used = str(payload_obj)
        
        # Prepare params for new analyzer signature
        response_data = {
            "body": result.get("body", result.get("response_body", "")),
            "status_code": result.get("status_code", 0),
            "elapsed_ms": result.get("elapsed_ms", result.get("response_time", 0)),
        }
        
        # Attack profile is in 'attack' variable
        finding = analyzer.analyze(
            response=response_data,
            attack_profile=attack,
            endpoint=f"{endpoint.get('method')} {endpoint.get('path')}",
            payload=payload_used
        )

        if finding:
            severity_value = getattr(finding.severity, "value", finding.severity)
            severity_text = str(severity_value).lower()
            title = finding.vulnerability_type or "Potential vulnerability detected"
            description = finding.evidence or "Potential vulnerability detected"
            new_findings.append(
                {
                    "type": finding.vulnerability_type,
                    "title": title,
                    "description": description,
                    "severity": severity_text,
                    "endpoint": finding.endpoint,
                    "method": endpoint.get("method", "GET"),
                    "evidence": finding.evidence,
                    "payload": payload_used,
                    "proof_of_concept": "",
                    "remediation": (
                        finding.recommendation
                        if getattr(finding, "recommendation", "")
                        else "Review input handling and validation."
                    ),
                }
            )

    return {"findings": state["findings"] + new_findings, "current_endpoint": idx + 1}


def should_continue(state: AgentState) -> Literal["plan", "end"]:
    if state["current_endpoint"] < len(state["endpoints"]):
        return "plan"
    return "end"


class Orchestrator:
    """
    This class uses LangGraph to create an agentic workflow that:
    1. Parses the OpenAPI spec
    2. Plans attack strategies
    3. Executes attacks
    4. Analyzes results
    5. Runs chaos testing (optional)
    6. Generates reports
    """
    
    def __init__(
        self,
        config: Dict[str, Any],
        chaos: bool = False,
        chaos_level: int = 3,
        resume: bool = False,
    ) -> None:
        """Initialize the orchestrator.
        
        Args:
            config: Configuration dictionary from chaos-kitten.yaml
            chaos: Whether to enable chaos mode
            chaos_level: Chaos intensity from 1 to 5
            resume: Whether to resume from a checkpoint
        """
        self.config = config
        self.chaos = chaos
        self.chaos_level = chaos_level
        self.resume = resume
        
        # State tracking
        self.vulnerabilities: List[Dict[str, Any]] = []
        self.checkpoint_path = Path(config.get("checkpoint_path", ".chaos-checkpoint.json"))

    def _build_graph(self, executor: Executor) -> StateGraph:
        """Build the LangGraph workflow."""
        if not HAS_LANGGRAPH:
            raise ImportError(
                "langgraph is not available. Please install it with 'pip install langgraph'."
            )
            
        workflow = StateGraph(AgentState)

        # Nodes
        workflow.add_node("recon", partial(run_recon, app_config=self.config))
        workflow.add_node("parse", parse_openapi)
        workflow.add_node("plan", plan_attacks)
        workflow.add_node("execute", partial(execute_and_analyze, executor=executor))
        
        # Edges
        workflow.add_edge(START, "recon")
        workflow.add_edge("recon", "parse")
        workflow.add_edge("parse", "plan")
        workflow.add_edge("plan", "execute")

        workflow.add_conditional_edges(
            "execute",
            should_continue,
            {
                "plan": "plan",
                "end": END
            }
        )

        return workflow.compile()

    async def run(self) -> Dict[str, Any]:
        """Run the full security scan.
        
        Returns:
            Scan results including vulnerabilities found
        """
        target_url = self.config.get("target", {}).get("base_url")
        spec_path = self.config.get("target", {}).get("openapi_spec", "")
        if not target_url:
            raise ValueError("Target URL not configured")
            
        console.print(f"ğŸš€ [bold cyan]Starting scan against {target_url}[/bold cyan]")
        
        # Initial state
        initial_state: AgentState = {
            "spec_path": spec_path,
            "base_url": target_url,
            "endpoints": [],
            "current_endpoint": 0,
            "planned_attacks": [],
            "results": [],
            "findings": [],
            "recon_results": {}
        }

        # Handle Resuming
        if self.resume:
            checkpoint = load_checkpoint(self.checkpoint_path)
            if checkpoint:
                current_hash = calculate_config_hash(self.config)
                if checkpoint.config_hash == current_hash:
                    console.print(f"ğŸ”„ [bold yellow]Resuming scan from {time.ctime(checkpoint.timestamp)}[/bold yellow]")
                    # Fill state from checkpoint
                    # We need to parse first to get full endpoints list for progress total
                    parser = OpenAPIParser(spec_path)
                    parser.parse()
                    endpoints = parser.get_endpoints()
                    
                    initial_state["endpoints"] = endpoints
                    initial_state["findings"] = checkpoint.vulnerabilities
                    initial_state["current_endpoint"] = len(checkpoint.completed_profiles)
                    
                    if initial_state["current_endpoint"] >= len(endpoints):
                        console.print("âœ¨ [bold green]All endpoints already completed![/bold green]")
                        # Skip execution but proceed to summary
                    else:
                        # Proceed with resumed state
                        pass
                else:
                    console.print("âš ï¸  [bold red]Config changed! Invalidating stale checkpoint and starting fresh.[/bold red]")
                    clean_checkpoint(self.checkpoint_path)
            else:
                console.print("âš ï¸  [bold yellow]No valid checkpoint found. Starting fresh.[/bold yellow]")

        final_state = initial_state
        
        if HAS_LANGGRAPH:
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                MofNCompleteColumn(),
                console=console,
            ) as progress:
                scan_task = progress.add_task("[cyan]Scanning endpoints...", total=None)

                async with Executor(target_url) as executor:
                    app = self._build_graph(executor)
                    
                    # If we resumed, we skip 'recon' and 'parse' nodes essentially by starting from 'plan'
                    # But LangGraph usually starts from START. 
                    # For simplicity, we'll let it re-run fast nodes or we can use a custom entry point.
                    # Re-running parse is fast. Recon might be slow.
                    # If recon was already done, it should be in initial_state too (needs to be saved in checkpoint).
                    
                    async for output in app.astream(initial_state):
                        for node_name, state_update in output.items():
                            final_state.update(state_update)
                            
                            if "endpoints" in state_update:
                                progress.update(
                                    scan_task, 
                                    total=len(final_state["endpoints"]), 
                                    completed=final_state["current_endpoint"]
                                )
                            
                            if node_name == "execute":
                                progress.advance(scan_task)
                                # Save checkpoint
                                completed_profiles = [
                                    f"{e['method']} {e['path']}" 
                                    for e in final_state['endpoints'][:final_state['current_endpoint']]
                                ]
                                checkpoint_data = CheckpointData(
                                    target_url=target_url,
                                    config_hash=calculate_config_hash(self.config),
                                    completed_profiles=completed_profiles,
                                    vulnerabilities=final_state["findings"],
                                    timestamp=time.time()
                                )
                                save_checkpoint(checkpoint_data, self.checkpoint_path)

            self.vulnerabilities = final_state.get("findings", [])
        else:
            console.print("âš ï¸  [bold red]LangGraph not installed. Skipping standard agentic scan.[/bold red]")
            self.vulnerabilities = []

        # Run chaos mode if enabled
        chaos_findings = []
        if self.chaos:
            from chaos_kitten.brain.chaos_engine import ChaosEngine
            
            engine = ChaosEngine(chaos_level=self.chaos_level)
            chaos_findings = await engine.run_chaos_tests(target_url)
            
            # Print chaos summary
            summary = engine.get_summary()
            if summary["total_findings"] > 0:
                print("\nğŸŒªï¸  [CHAOS] Summary:")
                print("   Critical: {}".format(summary["by_severity"].get("critical", 0)))
                print("   High: {}".format(summary["by_severity"].get("high", 0)))
                print("   Medium: {}".format(summary["by_severity"].get("medium", 0)))
            
        return {
            "vulnerabilities": self.vulnerabilities,
            "chaos_findings": chaos_findings,
            "summary": {
                "total_endpoints": len(final_state.get("endpoints", [])),
                "tested_endpoints": final_state.get("current_endpoint", 0),
                "vulnerabilities_found": len(self.vulnerabilities),
            },
        }
